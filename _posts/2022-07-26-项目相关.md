---
title: 项目相关
date: 2022-08-20 01:55:00 -0500
categories: [笔记]
tags: [操作系统]
pin: false
author: 01

toc: true
comments: true
typora-root-url: ../../Sterben-01.github.io
math: false
mermaid: true
 
---

# 项目相关

# UDP TCP

UDP不需要监听，自然服务端没有listen，UDP是无连接，自然客户端没有connect，服务端也没有accept

![unknown](/assets/blog_res/2022-07-26-%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3.assets/unknown.png)

# 同步模型

例子：你是一个老师，让学生做作业，学生做完作业后收作业。

- 同步阻塞：逐个收作业，先收A，再收B，接着是C、D，如果有一个学生还未做完，则你会**等到他写完，然后才继续收下一个**。
- 同步非阻塞：逐个收作业，先收A，再收B，接着是C、D，如果有一个学生还未做完，则你会**跳过该学生，继续去收下一个，收完了一圈再过来问学生写完没，如果没写完就再问一圈。**。
- select/poll：**学生写完了作业会举手，但是你不知道是谁举手，需要一个个的去询问**。
- epoll：**学生写完了作业会举手，你知道是谁举手，你直接去收作业**。

# 同步阻塞：

服务器执行到`accept`的时候，会阻塞，等待直到建立连接为止。服务器执行到`receive（Read）`部分的时候，也会阻塞，等待客户端发送数据。直到客户端发送完数据了才能继续。在这期间所有其他客户端想要建立链接都是不可以的，因为被阻塞在了客户端的`connect`这里。对于这种情况我们可以为每一个`connect`新建一个线程/进程。但是会消耗大量资源。

**写的部分也一样。会阻塞。**

单线程：某个 socket 阻塞，会影响到其他 socket 处理。

多线程：客户端较多时，会造成资源浪费，全部 socket 中可能每个时刻只有几个就绪。同时，线程的调度、上下文切换乃至它们占用的内存，可能都会成为瓶颈。**多线程解决的方式是在主线程`accept`后，新开一个线程对应一个客户端，读和写都在新的线程执行。**

# 同步非阻塞（忙轮询）

我们可以把**文件描述符**设为非阻塞。文件描述符设置为非阻塞可以解决`accept/receive(read)/send(write)`的阻塞。在非阻塞模式，所有的建立链接/读/写如果不能执行，则不会阻塞而是继续（循环）执行。所以我们可以把监听文件描述符设置为非阻塞来解决accept阻塞，也可以把读写文件描述符设置为非阻塞解决read write的阻塞。当监听文件描述符检测到连接后，既可以在主线程处理后续逻辑，也可以单开新线程进行处理。但是这种循环执行有个问题。每次循环都需要调用read write这种系统调用，会频繁切换内核态和用户态。浪费资源。

# IO多路复用

## SELECT

**首先，SELECT会拷贝一份我们需要监听的文件描述符集合到内核空间。然后内核帮助我们进行遍历，判断对应的文件描述符是否有修改动作。如果有就给对应的位置置为1，没有就会置为0哪怕原来是1。最后返回有几个事件就绪**。所以这个文件描述符集合每次会被修改。这就是为什么我们代码有两份文件描述符集合。但是假如我们有4个客户端 100 101 102 103需要检测。所以100-103的位置都是1。我们如果此时只有100 和 101 被修改了，那么这个数组里面将只有100 和 101是1。 102和103将会被置为0，不会被继续监听。所以我们有两个数组。一个是原始的只可以被set和clr进行手动设置和归零的。另一个是给内核的，内核可以修改的。所以我们select的时候给内核可修改版本。set和clr还是修改原始版本。然后在每一次的while循环一开始，更新内核版本为原来的需要监听的那几个。

**由于是内核帮助我们进行遍历，然后修改原文件描述符数组。所以最后我们还是要自己遍历一遍文件描述符数组找到到底哪几个文件描述符就绪了。也就是会重复遍历一次。最后我们还需要将自己原来的监听文件描述符数组拷贝回给让内核修改的那份（入参的那一份）**

### 优点：

- 不需要每个 FD 都进行一次系统调用，解决了我们自己使用同步非阻塞的时候频繁使用系统调用导致的频繁的用户态内核态切换问题

### 缺点：

- 有文件描述符数组的拷贝动作，（从用户空间拷贝到内核空间）消耗很大。而且是直接修改后拷贝回用户空间（整个数组全都拷贝）。所以需要两个数组，每次循环后都需要把我们自己保留的一份拷贝给内核的那一份里面。
- 有最大描述符限制
- 内核帮助我们遍历文件描述符数组的时候是线性遍历。所以效率较低
- `select`调用后，我们还是需要再次遍历一次文件描述符数组，找出具体修改的文件描述符。



**SELECT的文件描述符数组其实是bitmap。**

### 请注意。我们所谓的拷贝至内核指的是，将函数的参数拷贝至内核栈。普通参数传递的时候是直接把参数值入栈（用户态或者内核态）。但是系统调用的时候，由于内核不能相信任何用户空间的指针，所以会先把参数写入至寄存器，然后再把参数从寄存器拷贝至内核栈。所以我们SELECT会先把数组拷贝到内核空间，修改后再拷贝回用户空间。

## POLL

和`select`的两个区别

- 去掉了最大监听描述符数量的1024限制
- 不再需要每次重置监听描述符数组（重新赋值）**因为POLL的监听文件描述符数组实际上每个元素是储存了多种信息的结构体，类似`epoll`**

```c++
struct pollfd{
    int		fd;			//委托检测的文件描述符
    short	events;		//委托检测的事件
    short	revents;	//实际发生的事件
}
```

**内核会修改`revents`而不会修改`events`。这是主要区别**

# EPOLL

使用EPOLL的时候我们会先使用`epoll_create`创建一个epoll实例（eventpoll)。**但是这个实例被创建在了内核区**。创建后会返回一个epoll的文件描述符。我们正是通过这个文件描述符操作这个epoll实例。

- **我们所有要求epoll监听的文件描述符被储存在红黑树内。**

- 有一个就绪列表，用来添加所有已经就绪的文件描述符。这是一个双向链表
- 有一个等待队列。如果调用时没有时间就绪，就会阻塞，放入等待队列让出CPU以便后续唤醒。

我们每次使用`epoll_ctl`将一个需要监听的文件描述符添加至`eventpoll`的时候，会被封装成`epitem`后拷贝至内核空间，仅需拷贝一次。因为他会一直存在在里面。

- 每一个`epitem`也有一个等待队列，它会关联至一个回调函数(`ep_callback`)。也就是这个`epitem`对应的文件描述符就绪时，会调用这个回调函数来唤醒进程。

## 接收流程

- 服务端通过网卡接收到客户端消息。
- 网卡通过DMA写入内存。
- 发送中断信号给CPU，表示有数据到达。
- CPU调用中断处理程序处理。通过数据包的IP和端口号找到对应的socket套接字（文件描述符）。
- 将数据放入对应socket（文件描述符）的接收队列。
- 处理后会找到对应`epitem`的等待队列关联的回调函数（`ep_poll_callback`)。
- 回调函数会将`epitem`添加至就绪列表。
- 唤醒在等待队列中的进程。（如果进程处于睡眠状态）
- 进程判断就绪列表是否有就绪事件。
- 如果有就绪事件，**拷贝**至用户空间。

### epoll仅当添加监听的文件描述符（拷贝至内核空间） 和 有对应的就绪事件时（拷贝回用户空间）会发生拷贝。

## 优点

- **epoll对象一直被维护在内核态，所以仅有添加文件描述符时需要进行拷贝**
- **有就绪列表，所以可直接获知就绪事件（文件描述符）。无需重复遍历**
- **监听文件描述符数组储存在红黑树，搜索/添加/删除速度快**

## 缺点：

- 仅支持linux。跨平台性差。
- 比select复杂，移植性差。
- 在监听连接数和事件较少的情况下，select可能更优。因为比较简单。

## LT（水平）/ET（边缘）触发区别

LT模式的时候，只要`epoll_wait`检测到事件没有被处理完毕（比如没有读完），那么后续每次`epoll_wait`调用都会通知。

ET模式的时候，`epoll_wait`检测到事件后，仅通知一次。直到下次再次检测到事件后才继续通知。（就算没读完，也要等到下次新的事件到来后才能继续处理）

**ET模式下可以通知很多次。监听socket不用设置为oneshot是因为只存在一个主线程去操作这个监听socket**

## ONESHOT

oneshot指的某socket对应的fd事件最多只能被检测一次，不论你设置的是读写还是异常。

因为可能存在这种情况：如果epoll检测到了读事件，数据读完交给一个子线程去处理，

如果该线程处理的很慢，在此期间epoll在该socket上又检测到了读事件，则又给了另一个线程去处理，

则在同一时间会存在两个工作线程操作同一个socket。

EPOLLONESHOT这种方法，可以在epoll上注册这个事件，注册这个事件后，如果在处理完毕当前的socket后不再重新注册相关事件，

那么这个事件就不再响应了或者说触发了。

当处理完毕想要通知epoll可以再次处理的时候就要调用epoll_ctl重新注册(重置)文件描述符上的事件。这样前面的socket就不会出现竞态

**也就是说注册了 EPOLLONESHOT 事件的 socket 一旦被某个线程处理完毕， 该线程就应该立即重置这个 socket 上的 EPOLLONESHOT 事件，以确保这个 socket 下一次可读时，其 EPOLLIN 事件能被触发，进而让其他工作线程有机会继续处理这个 socket。**
